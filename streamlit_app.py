import streamlit as st
import pandas as pd
import google.generativeai as genai
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors

# --- é é¢é…ç½® (åªéœ€è¨­å®šä¸€æ¬¡) ---
st.set_page_config(
    page_title="SAS Hackathon - å®¢æˆ¶å–®ä¸€è¦–åœ–",
    page_icon="ğŸ¯",
    layout="wide"
)

# --- [æ–°å¢] Gemini API é‡‘é‘°è¨­å®š ---
# ä½¿ç”¨ st.secrets å®‰å…¨åœ°è®€å–æ‚¨çš„ API Key
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except (FileNotFoundError, KeyError):
    st.error("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° Gemini API Keyã€‚è«‹åœ¨ .streamlit/secrets.toml æª”æ¡ˆä¸­è¨­å®šæ‚¨çš„é‡‘é‘°ã€‚")
    st.stop()


# --- è³‡æ–™è¼‰å…¥ ---
@st.cache_data
def load_data(file_path):
    """å¾ CSV æª”æ¡ˆè¼‰å…¥è³‡æ–™"""
    try:
        df = pd.read_csv(file_path)
        if 'unique_id' in df.columns:
            df['unique_id'] = df['unique_id'].astype(str)
        return df
    except FileNotFoundError:
        st.error(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ '{file_path}'ã€‚è«‹ç¢ºèªè·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚")
        return pd.DataFrame()

# --- æ¨¡å‹èˆ‡é è™•ç† (å¿«å–è³‡æºä»¥åŠ é€Ÿ) ---
@st.cache_resource
def setup_models_and_data(df):
    """è³‡æ–™é è™•ç†ã€æ¨¡å‹è¨“ç·´ï¼Œä¸¦è¿”å›æ‰€æœ‰å¿…è¦çš„ç‰©ä»¶"""
    keep_columns = [
        'id', 'family_id', 'period_id', 'promo', 'phone_price',
        'data_consumption', 'text_consumption', 'voice_consumption',
        'technical_problem', 'complaints', 'total_data_consumption',
        'total_text_consumption', 'total_voice_consumption',
        'total_technical_problems', 'total_complaints',
        'time_since_technical_problems', 'time_since_complaints',
        'phone_balance', 'base_monthly_rate_phone', 'base_monthly_rate_plan',
        'age', 'workphone', 'plan_type', 'data', 'churn_in_12'
    ]
    existing_cols = [col for col in keep_columns if col in df.columns]
    model_df = df[existing_cols].copy()

    numeric_cols = ['phone_price', 'time_since_technical_problems', 'time_since_complaints']
    for col in numeric_cols:
        if col in model_df.columns:
            model_df[col] = pd.to_numeric(model_df[col], errors='coerce').fillna(0)

    categorical_cols = model_df.select_dtypes(include=['object', 'category']).columns.tolist()
    df_processed = pd.get_dummies(model_df, columns=categorical_cols, drop_first=True)

    if 'churn_in_12' not in df_processed.columns:
        st.error("è³‡æ–™é›†ä¸­ç¼ºå°‘ 'churn_in_12' ç›®æ¨™æ¬„ä½ï¼Œç„¡æ³•è¨“ç·´æ¨¡å‹ã€‚")
        return None

    y = df_processed['churn_in_12']
    X = df_processed.drop('churn_in_12', axis=1)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_scaled, y)

    nn = NearestNeighbors(n_neighbors=5)
    nn.fit(X_scaled)

    return {
        "model": model, "scaler": scaler, "nn": nn,
        "X_columns": X.columns, "processed_df": model_df
    }

# --- åŠŸèƒ½å‡½æ•¸ ---
def predict_churn(customer_dict, tools):
    cust_df = pd.DataFrame([customer_dict])
    cust_df = pd.get_dummies(cust_df)
    cust_df = cust_df.reindex(columns=tools["X_columns"], fill_value=0)
    cust_scaled = tools["scaler"].transform(cust_df)
    return tools["model"].predict_proba(cust_scaled)[0][1]

def find_similar_customers(customer_dict, tools):
    cust_df = pd.DataFrame([customer_dict])
    cust_df = pd.get_dummies(cust_df)
    cust_df = cust_df.reindex(columns=tools["X_columns"], fill_value=0)
    cust_scaled = tools["scaler"].transform(cust_df)
    distances, indices = tools["nn"].kneighbors(cust_scaled)
    return tools["processed_df"].iloc[indices[0]]

def customer_value(customer_dict):
    try:
        phone_price = float(customer_dict.get('phone_price', 0))
        base_rate = float(customer_dict.get('base_monthly_rate_plan', 0))
        data_consumption = float(customer_dict.get('total_data_consumption', 0))
        value = (phone_price + base_rate * 12 + data_consumption * 0.1)
    except (ValueError, TypeError):
        value = 0
    if value > 1000: grade = 'A (é«˜åƒ¹å€¼)'
    elif value > 500: grade = 'B (ä¸­åƒ¹å€¼)'
    else: grade = 'C (æ½›åŠ›å®¢æˆ¶)'
    return value, grade

# --- [æ–°å¢] Gemini AI åˆ†æå‡½æ•¸ ---
def get_gemini_analysis(original_customer_dict, similar_customers_df, question):
    """çµ„åˆ Prompt ä¸¦å‘¼å« Gemini API é€²è¡Œåˆ†æ"""
    model = genai.GenerativeModel('gemini-1.5-flash')
    
    # å°‡ DataFrame è½‰æ›ç‚ºæ›´æ˜“è®€çš„ Markdown æ ¼å¼
    similar_customers_md = similar_customers_df.to_markdown(index=False)
    original_customer_md = pd.DataFrame([original_customer_dict]).to_markdown(index=False)

    prompt = f"""
    **è§’è‰²ï¼š** ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é›»ä¿¡æ¥­å®¢æˆ¶æµå¤±åˆ†æå¸«ã€‚

    **ä»»å‹™ï¼š** æ ¹æ“šæˆ‘æä¾›çš„ã€Œç›®æ¨™å®¢æˆ¶ã€è³‡æ–™å’Œèˆ‡å…¶æœ€ç›¸ä¼¼çš„ã€Œç›¸ä¼¼å®¢æˆ¶ç¾¤é«”ã€è³‡æ–™ï¼Œæ·±å…¥åˆ†æä¸¦å›ç­”æˆ‘çš„å•é¡Œã€‚

    ---

    **ç›®æ¨™å®¢æˆ¶è³‡æ–™ï¼š**
    {original_customer_md}

    ---

    **ç›¸ä¼¼å®¢æˆ¶ç¾¤é«”ç‰¹å¾µ (å…±5ä½)ï¼š**
    {similar_customers_md}

    ---

    **æˆ‘çš„å•é¡Œï¼š** "{question}"

    **åˆ†ææŒ‡å¼•ï¼š**
    1.  **æ‰¾å‡ºå…±é€šé»ï¼š** è«‹ä»”ç´°è§€å¯Ÿé€™5ä½ç›¸ä¼¼å®¢æˆ¶çš„è³‡æ–™ï¼Œæ‰¾å‡ºä»–å€‘æœ‰å“ªäº›é¡¯è‘—çš„å…±åŒç‰¹å¾µï¼ˆä¾‹å¦‚ï¼šæ˜¯ä¸æ˜¯éƒ½å¾ˆå°‘æ”¶åˆ°ä¿ƒéŠ·(promo=0)ï¼Ÿæ˜¯ä¸æ˜¯éƒ½é‡åˆ°éæŠ€è¡“å•é¡Œ(technical_problem=1)ï¼Ÿæœˆç§Ÿè²»(base_monthly_rate_plan)æ˜¯å¦åé«˜æˆ–åä½ï¼Ÿï¼‰ã€‚
    2.  **é€£çµæµå¤±é¢¨éšªï¼š** å°‡é€™äº›å…±é€šç‰¹å¾µèˆ‡å®¢æˆ¶æµå¤±çš„å¯èƒ½æ€§é€£çµèµ·ä¾†ï¼Œæå‡ºä½ çš„å°ˆæ¥­è¦‹è§£ã€‚
    3.  **æå‡ºçµè«–ï¼š** æœ€å¾Œï¼Œè«‹ç”¨æ¸…æ™°ã€æœ‰æ¢ç†çš„æ–¹å¼ï¼ˆå»ºè­°ä½¿ç”¨æ¢åˆ—å¼ï¼‰ç¸½çµä½ çš„åˆ†æçµæœã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"å‘¼å« Gemini API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"


# --- UI é é¢æ¸²æŸ“ ---
def show_login_page():
    st.title("ä½¿ç”¨è€…ç™»å…¥")
    with st.form("login_form"):
        username = st.text_input("å¸³è™Ÿ")
        password = st.text_input("å¯†ç¢¼", type="password")
        if st.form_submit_button("ç™»å…¥"):
            if username and password:
                st.session_state['logged_in'] = True
                st.session_state['username'] = username
                st.rerun()
            else:
                st.error("è«‹è¼¸å…¥å¸³è™Ÿå’Œå¯†ç¢¼ï¼")

def show_analysis_dashboard():
    st.sidebar.title(f"æ­¡è¿ï¼Œ{st.session_state.get('username', 'ä½¿ç”¨è€…')}ï¼")
    st.sidebar.write("---")
    if st.sidebar.button("ç™»å‡º"):
        st.session_state['logged_in'] = False
        if 'username' in st.session_state: del st.session_state['username']
        st.rerun()

    st.title("ğŸ¯ å®¢æˆ¶å–®ä¸€è¦–åœ–å„€è¡¨æ¿")
    st.write("è«‹è¼¸å…¥å®¢æˆ¶çš„ `unique_id` ä»¥ç²å–å®Œæ•´çš„åˆ†æå ±å‘Šã€‚")

    with st.spinner('æ­£åœ¨æº–å‚™åˆ†æå·¥å…·ï¼Œé¦–æ¬¡åŸ·è¡Œå¯èƒ½éœ€è¦ä¸€é»æ™‚é–“...'):
        file_path = "C:/Users/andre/SAS_Hackthon/Score.csv"
        df = load_data(file_path)
        tools = setup_models_and_data(df)

    if df.empty or not tools:
        st.warning("è³‡æ–™è¼‰å…¥æˆ–æ¨¡å‹è¨“ç·´å¤±æ•—ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆèˆ‡æ¬„ä½ã€‚")
        return

    input_id = st.text_input("è¼¸å…¥å®¢æˆ¶ unique_id:", placeholder="ä¾‹å¦‚: id001")

    if st.button("åˆ†æå®¢æˆ¶"):
        # æ¸…é™¤ä¸Šä¸€æ¬¡çš„åˆ†æçµæœå’Œå°è©±ç´€éŒ„
        st.session_state.pop('similar_cust_df', None)
        st.session_state.pop('messages', None)
        st.session_state.pop('original_customer', None)

        if input_id:
            customer_record_df = df[df['unique_id'] == str(input_id)]
            if not customer_record_df.empty:
                customer_record = customer_record_df.iloc[0]
                customer_dict = customer_record.to_dict()

                st.session_state.original_customer = customer_dict # å„²å­˜ç›®æ¨™å®¢æˆ¶è³‡æ–™

                with st.container(border=True):
                    st.header(f"å®¢æˆ¶ID: {input_id} åˆ†æå ±å‘Š")
                    st.write("---")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        if 'EM_EVENTPROBABILITY' in customer_record:
                            prob = customer_record['EM_EVENTPROBABILITY']
                            st.metric(label="äº‹ä»¶ç™¼ç”Ÿæ©Ÿç‡", value=f"{prob:.2%}")
                        else:
                            st.info("'EM_EVENTPROBABILITY' æ¬„ä½ä¸å­˜åœ¨ã€‚")
                    with col2:
                        churn_rate = predict_churn(customer_dict, tools)
                        st.metric(label="é æ¸¬æµå¤±æ©Ÿç‡", value=f"{churn_rate:.2%}")
                    with col3:
                        value, grade = customer_value(customer_dict)
                        st.metric(label=f"æ½›åœ¨åƒ¹å€¼è©•æ¯”: {grade}", value=f"${value:,.0f}")
                    
                    st.write("---")
                    st.subheader("ç›¸ä¼¼å®¢æˆ¶ç¾¤é«”ç‰¹å¾µ")
                    similar_cust = find_similar_customers(customer_dict, tools)
                    st.dataframe(similar_cust)
                    
                    # å°‡ç›¸ä¼¼å®¢æˆ¶è³‡æ–™å­˜å…¥ session state ä»¥ä¾¿ AI åˆ†æ
                    st.session_state.similar_cust_df = similar_cust
            else:
                st.error(f"è³‡æ–™é›†ä¸­æ‰¾ä¸åˆ° unique_id: **{input_id}**")
        else:
            st.warning("è«‹å…ˆè¼¸å…¥ä¸€å€‹ unique_id å†é€²è¡ŒæŸ¥è©¢ã€‚")

    # --- [æ–°å¢] AI æ™ºæ…§åˆ†æèŠå¤©ä»‹é¢ ---
    if 'similar_cust_df' in st.session_state:
        st.write("---")
        st.subheader("ğŸ¤– AI æ™ºæ…§åˆ†æ")
        st.info("æ‚¨å¯ä»¥é‡å°ä¸Šæ–¹çš„ã€Œç›¸ä¼¼å®¢æˆ¶ç¾¤é«”ç‰¹å¾µã€è¡¨æ ¼æå•ï¼Œè®“ AI å”åŠ©æ‚¨åˆ†ææ½›åœ¨çš„æµå¤±åŸå› ã€‚")

        # åˆå§‹åŒ–å°è©±ç´€éŒ„
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # é¡¯ç¤ºæ­·å²å°è©±
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # æ¥æ”¶ä½¿ç”¨è€…è¼¸å…¥
        if prompt := st.chat_input("ç‚ºä»€éº¼é€™äº›å®¢æˆ¶å¯èƒ½æœƒæµå¤±ï¼Ÿæœ‰å“ªäº›å…±åŒé»ï¼Ÿ"):
            # å°‡ä½¿ç”¨è€…å•é¡ŒåŠ å…¥å°è©±ç´€éŒ„ä¸¦é¡¯ç¤º
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # å‘¼å« Gemini API ä¸¦é¡¯ç¤º AI å›æ‡‰
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨åˆ†æä¸­ï¼Œè«‹ç¨å€™..."):
                    response = get_gemini_analysis(
                        st.session_state.original_customer,
                        st.session_state.similar_cust_df,
                        prompt
                    )
                    st.markdown(response)
            
            # å°‡ AI å›æ‡‰åŠ å…¥å°è©±ç´€éŒ„
            st.session_state.messages.append({"role": "assistant", "content": response})

# --- ä¸»æ‡‰ç”¨ç¨‹å¼æµç¨‹æ§åˆ¶å™¨ ---
def main():
    if 'logged_in' not in st.session_state:
        st.session_state['logged_in'] = False
    if st.session_state['logged_in']:
        show_analysis_dashboard()
    else:
        show_login_page()

if __name__ == "__main__":
    main()